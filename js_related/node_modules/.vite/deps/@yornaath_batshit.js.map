{
  "version": 3,
  "sources": ["../../../../../../../AppData/Local/Yarn/Berry/cache/@yornaath-batshit-npm-0.10.1-c034b55ef0-10c0.zip/node_modules/@yornaath/batshit/src/deferred.ts", "../../../../../../../AppData/Local/Yarn/Berry/cache/@yornaath-batshit-npm-0.10.1-c034b55ef0-10c0.zip/node_modules/@yornaath/batshit/src/index.ts"],
  "sourcesContent": ["/**\n * A deffered value that can be resolved at a later time outside of its closure.\n * @generic T - value of the deffered\n */\nexport type Deferred<T> = {\n  resolve: (value: T | PromiseLike<T>) => void\n  reject: (reason?: any) => void\n  value: Promise<T>\n}\n\n/**\n * Create a new Deffered\n *\n * @generic T - value of the deffered\n * @returns Deferred<T>\n */\nexport const deferred = <T>(): Deferred<T> => {\n  let resolve!: Deferred<T>['resolve']\n  let reject!: Deferred<T>['reject']\n\n  const value = new Promise<T>((_resolve, _reject) => {\n    resolve = _resolve\n    reject = _reject\n  })\n\n  return {\n    resolve,\n    reject,\n    value,\n  }\n}\n\n/**\n * Type guard for Deffered values.\n *\n * @generic T - value of the deffered\n * @param value any\n * @returns value is Deferred<T>\n */\nexport const isDeferred = <T>(value: any): value is Deferred<T> =>\n  typeof value === 'object' &&\n  value !== null &&\n  'resolve' in value &&\n  'reject' in value &&\n  'value' in value &&\n  'then' in value.value", "import type { DevtoolsListener } from \"@yornaath/batshit-devtools\";\nimport { Deferred, deferred } from \"./deferred\";\n/**\n * Batcher.\n * A batch manager that will batch requests for a certain data type within a given window.\n *\n * @generic T - The type of the data.\n * @generic Q - item query type\n * @generic C - the context of the batcher passed to the fetcher function\n */\nexport type Batcher<T, Q, R = T> = {\n  /**\n   * Schedule a get request for a query.\n   *\n   * @generic T - The type of the data.\n   * @generic Q - item query type\n   * @param query Q\n   * @returns Promise<T>\n   */\n  fetch: (query: Q) => Promise<R>;\n};\n\n/**\n * Config needed to create a Batcher\n *\n * @generic T - The type of the data.\n * @generic Q - item query type\n * @generic C - the context of the batcher passed to the fetcher function\n */\nexport type BatcherConfig<T, Q, R> = {\n  /**\n   * The function that makes the batched request for the current batch queries\n   *\n   * @param queries Q[]\n   * @returns Promise<T\n   */\n  fetcher: (queries: Q[]) => Promise<T>;\n  /**\n   * The scheduling function.\n   */\n  scheduler?: BatcherScheduler;\n  /**\n   * Correlate an item by its query. Used to extract the correct value from the batch of items\n   * to the correct query used to fetch it.\n   *\n   * @param query Q\n   * @returns string\n   */\n  resolver: (items: T, query: Q) => R;\n  /**\n   * Display name of the batcher. Used for debugging and devtools.\n   */\n  name?: string;\n};\n\n/**\n * A function to schedule batch execution timing\n */\nexport type BatcherScheduler = {\n  /**\n   * A scheduler function.\n   *\n   * @param start number - time stamp when the current batch started queuing fetches.\n   * @param latest number - time stamp of the latest queued fetch.\n   * @returns number - the number of ms to wait from latest queued fetch until executing batchh fetch call.\n   */\n  (start: number, latest: number, batchSize: number): Schedule;\n};\n\n/**\n * A schedule for when to execute a batched fetch call.\n */\nexport type Schedule = number | \"immediate\" | \"never\";\n\nexport type BatcherMemory<T, Q> = {\n  seq: number;\n  batch: Set<Q>;\n  currentRequest: Deferred<T>;\n  timer?: NodeJS.Timeout | undefined;\n  start?: number | null;\n  latest?: number | null;\n};\n\n/**\n * Create a batch manager for a given collection of a data type.\n * Will batch all .get calls given inside a scheduled time window into a singel request.\n *\n * @generic T - The type of the data.\n * @generic Q - item query type\n * @generic C - the context of the batcher passed to the fetcher function\n * @param config BatcherConfig<T, Q>\n * @returns Batcher<T, Q>\n */\nexport const create = <T, Q, R = T>(\n  config: BatcherConfig<T, Q, R>,\n  memory?: BatcherMemory<T, Q>\n): Batcher<T, Q, ReturnType<(typeof config)[\"resolver\"]>> => {\n  const name = config.name ?? `batcher:${Math.random().toString(16).slice(2)})`;\n\n  const scheduler: BatcherScheduler = config.scheduler ?? windowScheduler(10);\n\n  const devtools: DevtoolsListener<any, any> | undefined =\n    globalThis.__BATSHIT_DEVTOOLS__?.for(name);\n\n  let mem: BatcherMemory<T, Q> = memory ?? {\n    seq: 0,\n    batch: new Set<Q>(),\n    currentRequest: deferred<T>(),\n    timer: undefined,\n    start: null,\n    latest: null,\n  };\n\n  devtools?.create({ seq: mem.seq });\n\n  const nextBatch = () => {\n    mem.batch = new Set();\n    mem.currentRequest = deferred<T>();\n    mem.timer = undefined;\n    mem.start = null;\n    mem.latest = null;\n  };\n\n  const fetch = (query: Q): Promise<R> => {\n    if (!mem.start) mem.start = Date.now();\n    mem.latest = Date.now();\n\n    mem.batch.add(query);\n    clearTimeout(mem.timer);\n\n    const scheduled = scheduler(mem.start, mem.latest, mem.batch.size);\n\n    devtools?.queue({\n      seq: mem.seq,\n      query,\n      batch: [...mem.batch],\n      scheduled,\n      latest: mem.latest,\n      start: mem.start,\n    });\n\n    const fetchBatch = () => {\n      const currentSeq = mem.seq;\n      const req = config.fetcher([...mem.batch]);\n      const currentRequest = mem.currentRequest;\n\n      devtools?.fetch({ seq: currentSeq, batch: [...mem.batch] });\n\n      nextBatch();\n\n      req\n        .then((data) => {\n          devtools?.data({ seq: currentSeq, data });\n          currentRequest.resolve(data);\n        })\n        .catch((error) => {\n          devtools?.error({ seq: currentSeq, error });\n          currentRequest.reject(error);\n        });\n\n      mem.seq++;\n\n      return req;\n    };\n\n    if (scheduled === \"immediate\") {\n      const req = mem.currentRequest;\n      fetchBatch();\n      return req.value.then((items) => config.resolver(items, query));\n    } else if (scheduled === \"never\") {\n      return mem.currentRequest.value.then((items) =>\n        config.resolver(items, query)\n      );\n    } else {\n      mem.timer = setTimeout(fetchBatch, scheduled);\n      return mem.currentRequest.value.then((items) =>\n        config.resolver(items, query)\n      );\n    }\n  };\n\n  return { fetch };\n};\n\n/**\n * Resolve by item field of items when response is an array.\n * Create a euquality check to check if the query matches a given key on the item data.\n *\n * @param key keyof T\n * @returns (item:T extends Array<A>, query: Q) => A\n */\nexport const keyResolver =\n  <T extends Array<any>, Q, R = T extends Array<infer A> ? A : never>(\n    key: T extends Array<infer A> ? keyof A : never\n  ) =>\n  (items: T, query: Q): R =>\n    items.find((item) => item[key] == query) ?? null;\n\n/**\n * Resolve by record index when response is an object.\n * Create a euquality check to check if the query matches a given key on the item data.\n *\n * @returns (item:T extends Record<_, A>, query: Q) => A\n */\nexport const indexedResolver =\n  <T extends Record<any, any>, Q>() =>\n  (itemsIndex: T, query: Q) =>\n    itemsIndex[query] ?? null;\n\n/**\n * Give a window in ms where all queued fetched made within the window will be batched into\n * one singler batch fetch call.\n *\n * @param ms number\n * @returns BatcherScheduler\n */\nexport const windowScheduler: (ms: number) => BatcherScheduler =\n  (ms) => (start, latest) => {\n    const spent = latest - start;\n    return ms - spent;\n  };\n\n/**\n * Give a buffer time in ms. Will give another buffer window when queueing a fetch.\n *\n * @param ms number\n * @returns BatcherScheduler\n */\nexport const bufferScheduler: (ms: number) => BatcherScheduler = (ms) => () => {\n  return ms;\n};\n\n/**\n * Same as windowScheduler, will batch calls made within a window of time OR when the max batch size is reached.\n *\n * @param config: {windowMs: number; maxBatchSize: number;}\n * @returns BatcherScheduler\n */\nexport const windowedFiniteBatchScheduler: (config: {\n  windowMs: number;\n  maxBatchSize: number;\n}) => BatcherScheduler =\n  ({ windowMs, maxBatchSize }) =>\n  (start, latest, batchSize) => {\n    if (batchSize >= maxBatchSize) return \"immediate\";\n    const spent = latest - start;\n    return windowMs - spent;\n  };\n\n/**\n * Will batch calls when the max batch size is reached.\n *\n * @param config: {maxBatchSize: number;}\n * @returns BatcherScheduler\n */\nexport const maxBatchSizeScheduler: (config: {\n  maxBatchSize: number;\n}) => BatcherScheduler =\n  ({ maxBatchSize }) =>\n  (_start, _latest, batchSize) => {\n    if (batchSize >= maxBatchSize) return \"immediate\";\n    return \"never\";\n  };\n"],
  "mappings": ";;;AAgBO,IAAM,WAAW,MAAqB;AAC3C,MAAI;AACJ,MAAI;AAEJ,QAAM,QAAQ,IAAI,QAAW,CAAC,UAAU,YAAW;AACjD,cAAU;AACV,aAAS;EACX,CAAC;AAED,SAAO;IACL;IACA;IACA;;AAEJ;;;IC+Da,SAAS,CACpB,QACA,WAC0D;;AAC1D,QAAM,OAAO,OAAO,QAAQ,WAAW,KAAK,OAAM,EAAG,SAAS,EAAE,EAAE,MAAM,CAAC,CAAC;AAE1E,QAAM,YAA8B,OAAO,aAAa,gBAAgB,EAAE;AAE1E,QAAM,YACJ,gBAAW,yBAAX,mBAAiC,IAAI;AAEvC,MAAI,MAA2B,UAAU;IACvC,KAAK;IACL,OAAO,oBAAI,IAAG;IACd,gBAAgB,SAAQ;IACxB,OAAO;IACP,OAAO;IACP,QAAQ;;AAGV,uCAAU,OAAO,EAAE,KAAK,IAAI,IAAG;AAE/B,QAAM,YAAY,MAAK;AACrB,QAAI,QAAQ,oBAAI,IAAG;AACnB,QAAI,iBAAiB,SAAQ;AAC7B,QAAI,QAAQ;AACZ,QAAI,QAAQ;AACZ,QAAI,SAAS;EACf;AAEA,QAAM,QAAQ,CAAC,UAAwB;AACrC,QAAI,CAAC,IAAI;AAAO,UAAI,QAAQ,KAAK,IAAG;AACpC,QAAI,SAAS,KAAK,IAAG;AAErB,QAAI,MAAM,IAAI,KAAK;AACnB,iBAAa,IAAI,KAAK;AAEtB,UAAM,YAAY,UAAU,IAAI,OAAO,IAAI,QAAQ,IAAI,MAAM,IAAI;AAEjE,yCAAU,MAAM;MACd,KAAK,IAAI;MACT;MACA,OAAO,CAAC,GAAG,IAAI,KAAK;MACpB;MACA,QAAQ,IAAI;MACZ,OAAO,IAAI;IACZ;AAED,UAAM,aAAa,MAAK;AACtB,YAAM,aAAa,IAAI;AACvB,YAAM,MAAM,OAAO,QAAQ,CAAC,GAAG,IAAI,KAAK,CAAC;AACzC,YAAM,iBAAiB,IAAI;AAE3B,2CAAU,MAAM,EAAE,KAAK,YAAY,OAAO,CAAC,GAAG,IAAI,KAAK,EAAC;AAExD,gBAAS;AAET,UACG,KAAK,CAAC,SAAQ;AACb,6CAAU,KAAK,EAAE,KAAK,YAAY,KAAI;AACtC,uBAAe,QAAQ,IAAI;MAC7B,CAAC,EACA,MAAM,CAAC,UAAS;AACf,6CAAU,MAAM,EAAE,KAAK,YAAY,MAAK;AACxC,uBAAe,OAAO,KAAK;MAC7B,CAAC;AAEH,UAAI;AAEJ,aAAO;IACT;AAEA,QAAI,cAAc,aAAa;AAC7B,YAAM,MAAM,IAAI;AAChB,iBAAU;AACV,aAAO,IAAI,MAAM,KAAK,CAAC,UAAU,OAAO,SAAS,OAAO,KAAK,CAAC;IAC/D,WAAU,cAAc,SAAS;AAChC,aAAO,IAAI,eAAe,MAAM,KAAK,CAAC,UACpC,OAAO,SAAS,OAAO,KAAK,CAAC;IAEhC,OAAM;AACL,UAAI,QAAQ,WAAW,YAAY,SAAS;AAC5C,aAAO,IAAI,eAAe,MAAM,KAAK,CAAC,UACpC,OAAO,SAAS,OAAO,KAAK,CAAC;IAEhC;EACH;AAEA,SAAO,EAAE,MAAK;AAChB;AASO,IAAM,cACX,CACE,QAEF,CAAC,OAAU,UACT,MAAM,KAAK,CAAC,SAAS,KAAK,GAAG,KAAK,KAAK,KAAK;IAQnC,kBACX,MACA,CAAC,YAAe,UACd,WAAW,KAAK,KAAK;AASlB,IAAM,kBACX,CAAC,OAAO,CAAC,OAAO,WAAU;AACxB,QAAM,QAAQ,SAAS;AACvB,SAAO,KAAK;AACd;AAQW,IAAA,kBAAoD,CAAC,OAAO,MAAK;AAC5E,SAAO;AACT;IAQa,+BAIX,CAAC,EAAE,UAAU,aAAY,MACzB,CAAC,OAAO,QAAQ,cAAa;AAC3B,MAAI,aAAa;AAAc,WAAO;AACtC,QAAM,QAAQ,SAAS;AACvB,SAAO,WAAW;AACpB;AAQW,IAAA,wBAGX,CAAC,EAAE,aAAY,MACf,CAAC,QAAQ,SAAS,cAAa;AAC7B,MAAI,aAAa;AAAc,WAAO;AACtC,SAAO;AACT;",
  "names": []
}
